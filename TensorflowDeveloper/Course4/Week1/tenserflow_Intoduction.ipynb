{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "WNG9TTjAmAd-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Getting STarted with TenserFlow [Week1]**"
      ],
      "metadata": {
        "id": "77z17wcjmLrN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBwlWo7rcJse"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([keras.layers.Dense(units=1,input_shape =[1])])"
      ],
      "metadata": {
        "id": "a2wtgUPfcXdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss = 'mean_squared_error')"
      ],
      "metadata": {
        "id": "lSbZZ8mncx5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xs = np.array([-1.0,0.0,1.0,2.0,3.0,4.0], dtype = float)\n",
        "# ys = np.array([-3.0,-1.0,1.0,3.0,5.0,7.0], dtype = float)\n",
        "xs = np.array([0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0], dtype = float)\n",
        "ys = np.array([0.5,1.0,1.5,2.0,2.5,3.0,3.5,4.0], dtype = float)\n",
        "model.fit(xs,ys,epochs=500)"
      ],
      "metadata": {
        "id": "7AtOLgswdCYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([10.0,20.0])"
      ],
      "metadata": {
        "id": "3c6c9Y8Ldn-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wb_ChiB5dztZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Now Playing around with Mnish Fashion Data to train a model to understand the clothes [Week 2]***"
      ],
      "metadata": {
        "id": "rmY7fycHkdR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the dataset API\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# Load the dataset\n",
        "(x_train, y_train),(x_test, y_test) = fmnist.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "nEQn6-cKkl72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,logs = {}):\n",
        "    print()\n",
        "    if logs.get(\"accuracy\")>0.9:\n",
        "      print(f\"stopping the model training at epochs-> {epoch}\")\n",
        "      self.model.stop_training=True\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "_QUSlgJy5QRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "index=40\n",
        "np.set_printoptions(linewidth=320)\n",
        "# print(f\"Labels->{y_train[index]}\")\n",
        "# print(f\"input array->{x_train[index]}\")\n",
        "# plt.imshow(x_train[index])"
      ],
      "metadata": {
        "id": "ifF3_2GllEzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                            tf.keras.layers.Dense(1024,activation=tf.nn.relu),\n",
        "                            tf.keras.layers.Dense(10,activation=tf.nn.softmax)])"
      ],
      "metadata": {
        "id": "M65y7TbVldk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(x_train,y_train,epochs=5) #, callbacks = [callbacks])"
      ],
      "metadata": {
        "id": "_hQ5Q8_Am1Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "id": "WO2CSscunlAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification = model.predict(x_test)"
      ],
      "metadata": {
        "id": "12hH5KiXn4Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification[0])\n",
        "print(y_test[0])"
      ],
      "metadata": {
        "id": "fEJEz5uspqf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Enhancing Vision with Convolutional Neural Networks [Week 3]***"
      ],
      "metadata": {
        "id": "kKYUaXN_qjjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape = (28,28,1)),\n",
        "                                    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "                                   tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "                                    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "                                   tf.keras.layers.Flatten(),\n",
        "                                   tf.keras.layers.Dense(128,activation='relu'),\n",
        "                                   tf.keras.layers.Dense(10,activation='softmax')])\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "print(\"############################ Training the Model ############################\")\n",
        "model.fit(x_train,y_train,epochs=5, callbacks=[callbacks])\n",
        "print(\"############################ Testing the Model ############################\")\n",
        "model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "id": "KhQdIHDApzf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test[:100])"
      ],
      "metadata": {
        "id": "pOfw1zbA6f_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import models\n",
        "\n",
        "f, axarr = plt.subplots(3,4)\n",
        "\n",
        "first_image = 0\n",
        "second_image = 23\n",
        "third_image = 28\n",
        "convolution_layer=1\n",
        "\n",
        "layers_output = [layer.output for layer in model.layers]\n",
        "activation_model = models.Model(inputs = model.input, outputs = layers_output)\n",
        "\n",
        "for index in range(0,4):\n",
        "  f1 = activation_model.predict(x_test[first_image].reshape(1,28,28,1))[index]\n",
        "  axarr[0,index].imshow(f1[0, :, :, convolution_layer], cmap='inferno')\n",
        "  axarr[0,index].grid(False)\n",
        "  \n",
        "  f2 = activation_model.predict(x_test[second_image].reshape(1,28,28,1))[index]\n",
        "  axarr[1,index].imshow(f2[0,:,:,convolution_layer], cmap='inferno')\n",
        "  axarr[1,index].grid(False)\n",
        "  \n",
        "  f3 = activation_model.predict(x_test[third_image].reshape(1,28,28,1))[index]\n",
        "  axarr[2,index].imshow(f3[0,:,:,convolution_layer], cmap='inferno')\n",
        "  axarr[2,index].grid(False)"
      ],
      "metadata": {
        "id": "ut3olSzRrvKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Understanding the functionality of COnvolution and MaxPooling [Week3]***"
      ],
      "metadata": {
        "id": "WNG9TTjAmAd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import misc\n",
        "\n",
        "ascent_image = misc.ascent()\n",
        "plt.grid(False)\n",
        "plt.gray()\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(ascent_image)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "dn4rFPV48aht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_image = np.copy(ascent_image)\n",
        "size_x = transformed_image.shape[0]\n",
        "size_y = transformed_image.shape[1]\n",
        "print(size_x)\n",
        "print(size_y)"
      ],
      "metadata": {
        "id": "LC2c7OgynGF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with different values and see the effect\n",
        "# filter = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]]\n",
        "\n",
        "# A couple more filters to try for fun!\n",
        "# filter = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
        "filter = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
        "\n",
        "# If all the digits in the filter don't add up to 0 or 1, you \n",
        "# should probably do a weight to get it to do so\n",
        "# so, for example, if your weights are 1,1,1 1,2,1 1,1,1\n",
        "# They add up to 10, so you would set a weight of .1 if you want to normalize them\n",
        "weight  = 1"
      ],
      "metadata": {
        "id": "WHuM8MQGnynj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(1,size_x-1):\n",
        "  for y in range(1,size_y-1):\n",
        "    convolution = 0.0\n",
        "    convolution = convolution+(ascent_image[x-1][y-1]*filter[0][0])\n",
        "    convolution = convolution+(ascent_image[x-1][y]*filter[0][1])\n",
        "    convolution = convolution+(ascent_image[x-1][y+1]*filter[0][2])\n",
        "    convolution = convolution+(ascent_image[x][y-1]*filter[1][0])\n",
        "    convolution = convolution+(ascent_image[x][y]*filter[1][1])\n",
        "    convolution = convolution+(ascent_image[x][y+1]*filter[1][2])\n",
        "    convolution = convolution+(ascent_image[x+1][y-1]*filter[2][0])\n",
        "    convolution = convolution+(ascent_image[x+1][y]*filter[2][1])\n",
        "    convolution = convolution+(ascent_image[x+1][y+1]*filter[2][2])\n",
        "    convolution = convolution*1\n",
        "    if convolution<0:\n",
        "      convolution = 0\n",
        "    elif convolution>255:\n",
        "      convolution = 255\n",
        "    transformed_image[x][y] = convolution"
      ],
      "metadata": {
        "id": "8TqCQn4qoAH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.gray()\n",
        "plt.grid(False)\n",
        "plt.imshow(transformed_image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XIB_K8w0pQMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_x = size_x//2\n",
        "new_y = size_y//2\n",
        "new_image = np.zeros((new_x,new_y))\n",
        "for x in range(0,size_x,2):\n",
        "  for y in range(0,size_y,2):\n",
        "    pixels = []\n",
        "    pixels.append(transformed_image[x,y])\n",
        "    pixels.append(transformed_image[x+1,y])\n",
        "    pixels.append(transformed_image[x,y+1])\n",
        "    pixels.append(transformed_image[x+1,y+1])\n",
        "    new_image[x//2,y//2] = max(pixels)\n",
        "\n",
        "plt.gray()\n",
        "plt.grid(False)\n",
        "plt.imshow(new_image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AUewDNAkpbqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Training with ImageDataGenerator [Week 4]***"
      ],
      "metadata": {
        "id": "VXkz77zPu5ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install this package to use Colab's GPU for training\n",
        "!apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6"
      ],
      "metadata": {
        "id": "ubSuU5tZqhaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip"
      ],
      "metadata": {
        "id": "f_zdNt0zu-5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "localZip = \"./horse-or-human.zip\"\n",
        "zip_ref = zipfile.ZipFile(localZip, 'r')\n",
        "zip_ref.extractall(\"./horse-or-human\")\n",
        "zip_ref.close()\n"
      ],
      "metadata": {
        "id": "iyUY5Vrrwo2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_horse_dir = os.path.join(\"./horse-or-human/horses\")\n",
        "train_human_dir = os.path.join(\"./horse-or-human/humans\")\n",
        "\n",
        "horse_list_names = os.listdir(train_horse_dir)\n",
        "humans_list_names = os.listdir(train_human_dir)\n",
        "print(horse_list_names[:10])\n",
        "print(humans_list_names[:10])\n",
        "print(f\"length of human images are-->{len(os.listdir(train_horse_dir))}\")\n",
        "print(f\"length of horses images are-->{len(os.listdir(train_horse_dir))}\")"
      ],
      "metadata": {
        "id": "IfMjgxN3xA6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "nrows, ncols = 4,4\n",
        "picindex = 0\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "picindex+=8\n",
        "\n",
        "human_images = [os.path.join(train_human_dir, fnames) for fnames in humans_list_names[picindex-8:picindex]]\n",
        "horse_images = [os.path.join(train_horse_dir, fnames) for fnames in horse_list_names[picindex-8:picindex]]\n",
        "\n",
        "for index, fname in enumerate(horse_images+human_images):\n",
        "    sp = plt.subplot(nrows,ncols, index+1)\n",
        "    sp.axis(\"off\")\n",
        "    img = mpimg.imread(fname)\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4gWv5YkcyNUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,(3,3),activation=\"relu\", input_shape=(300,300,3)),\n",
        "                                    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "                                    tf.keras.layers.Conv2D(32,(3,3),activation=\"relu\"),\n",
        "                                    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "                                    tf.keras.layers.Conv2D(64,(3,3),activation=\"relu\"),\n",
        "                                    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "                                    tf.keras.layers.Conv2D(128,(3,3),activation=\"relu\"),\n",
        "                                    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "                                    tf.keras.layers.Conv2D(256,(3,3),activation=\"relu\"),\n",
        "                                    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = RMSprop(learning_rate=0.001),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "0Gm4sFjJzfRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_generator = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "train_images = image_generator.flow_from_directory(\n",
        "    \"./horse-or-human\",\n",
        "    batch_size = 128,\n",
        "    target_size = (300,300,),\n",
        "    class_mode = 'binary'\n",
        ")"
      ],
      "metadata": {
        "id": "tiypmyuS1jth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, steps_per_epoch=8, epochs = 15, verbose=2)"
      ],
      "metadata": {
        "id": "qKaa0mwH2jEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  file_path = '/content/'+fn\n",
        "  img = image.load_img(file_path, target_size=(300,300,))\n",
        "  x = image.img_to_array(img)\n",
        "  x /=255\n",
        "  x = np.expand_dims(x,axis=0)\n",
        "  images = np.vstack([x])\n",
        "  prediction = model.predict(images, batch_size=10)\n",
        "  print(prediction[0])\n",
        "  if prediction[0]>0.5:\n",
        "    print(\"Its Horses\")\n",
        "  else:\n",
        "    print(\"Its Humans\")"
      ],
      "metadata": {
        "id": "kLH-A94U23oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tensorflow.keras.preprocessing import image\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "\n",
        "human_images = [os.path.join(train_human_dir, fnames) for fnames in humans_list_names]\n",
        "horse_images = [os.path.join(train_horse_dir, fnames) for fnames in horse_list_names]\n",
        "\n",
        "img_path = random.choice(horse_images+human_images)\n",
        "\n",
        "img = image.load_img(img_path, target_size=(300,300,))\n",
        "x = image.img_to_array(img)\n",
        "x = x.reshape((1,)+x.shape)\n",
        "x /= 255\n",
        "\n",
        "succesfive_featur_maps = visualization_model.predict(x)\n",
        "layers_name = [layer.name for layer in model.layers[1:]]\n",
        "\n",
        "for layer_name, feature_map in zip(layers_name, succesfive_featur_maps):\n",
        "\n",
        "  if len(feature_map.shape)==4:\n",
        "    n_features = feature_map.shape[-1]\n",
        "    size = feature_map.shape[1]\n",
        "    display_grid = np.zeros((size, size*n_features))\n",
        "    for idx in range(n_features):\n",
        "      x = feature_map[0,:,:,idx]\n",
        "      x-=x.mean()\n",
        "      x/=x.std()\n",
        "      x*=64\n",
        "      x+=128\n",
        "      x = np.clip(x,0,255).astype('uint8')\n",
        "      display_grid[:, idx*size:(idx+1)*size] = x\n",
        "    \n",
        "    scale = 20./n_features\n",
        "    plt.figure(figsize = (n_features*scale, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, cmap = \"viridis\", aspect=\"auto\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Gjuc0gUL4x_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os, signal\n",
        "# os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "metadata": {
        "id": "NVrNhvxm-Z1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the training set\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n"
      ],
      "metadata": {
        "id": "fwko3BzFAB9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the validation set\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip\n"
      ],
      "metadata": {
        "id": "ztHv6CUvL-i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "validaion_zip = './validation-horse-or-human.zip'\n",
        "validation_ref = zipfile.ZipFile(validaion_zip, 'r')\n",
        "validation_ref.extractall('./validation-horse-or-human')\n",
        "validation_ref.close()\n",
        "\n",
        "validaion_zip = './horse-or-human.zip'\n",
        "validation_ref = zipfile.ZipFile(validaion_zip, 'r')\n",
        "validation_ref.extractall('./horse-or-human')\n",
        "validation_ref.close()"
      ],
      "metadata": {
        "id": "RfVVswoYMBeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_horses = os.path.join('./horse-or-human/horses')\n",
        "train_humans = os.path.join('./horse-or-human/humans')\n",
        "Validation_horses = os.path.join('./validation-horse-or-human/horses')\n",
        "Validation_humans = os.path.join('./validation-horse-or-human/humans')\n",
        "\n",
        "train_horses_files = os.listdir(train_horses)\n",
        "train_humans_files = os.listdir(train_humans)\n",
        "Validation_horses_files = os.listdir(Validation_horses)\n",
        "Validation_humans_files = os.listdir(Validation_humans)\n",
        "print(f\"length of trrain_horses-->{len(os.listdir(train_horses))}\")\n",
        "print(f\"length of train_humans-->{len(os.listdir(train_humans))}\")\n",
        "print(f\"length of Validation_horses-->{len(os.listdir(Validation_horses))}\")\n",
        "print(f\"length of Validation_humans-->{len(os.listdir(Validation_humans))}\")\n",
        "print(f\"10 example of train_horses--->{train_horses_files[:10]}\")\n",
        "print(f\"10 example of train_humans--->{train_humans_files[:10]}\")\n",
        "print(f\"10 example of Validation_horses--->{Validation_horses_files[:10]}\")\n",
        "print(f\"10 example of Validation_humans--->{Validation_humans_files[:10]}\")"
      ],
      "metadata": {
        "id": "B1DNxalQMt1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "n_rows, n_cols = 4, 4\n",
        "pcIndex = 0\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(n_cols*4,n_rows*4)\n",
        "pcIndex += 4\n",
        "\n",
        "training_horse_images = [os.path.join(train_horses, fname) for fname in train_horses_files[pcIndex-4:pcIndex]]\n",
        "training_human_images = [os.path.join(train_humans, fname) for fname in train_humans_files[pcIndex-4:pcIndex]]\n",
        "validation_horse_images = [os.path.join(Validation_horses, fname) for fname in Validation_horses_files[pcIndex-4:pcIndex]]\n",
        "validation_human_images = [os.path.join(Validation_humans, fname) for fname in Validation_humans_files[pcIndex-4:pcIndex]]\n",
        "\n",
        "training_horse_images = [os.path.join(train_horses, fname) for fname in train_horses_files[pcIndex-4:pcIndex]]\n",
        "for idx, img_path in enumerate(training_horse_images+training_human_images+validation_horse_images+validation_human_images):\n",
        "  subplot = plt.subplot(n_rows, n_cols, idx+1)\n",
        "  subplot.axis(\"off\")\n",
        "  image = mpimg.imread(img_path)\n",
        "  plt.imshow(image)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ky98NuSBNlUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16,(3,3), activation='relu',input_shape=(150,150,3)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(32,(3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64,(3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "dvH83BUPQV1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=RMSprop(learning_rate=0.001))"
      ],
      "metadata": {
        "id": "JepzrY3mRKJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_gen = ImageDataGenerator(rescale = 1/255)\n",
        "Validation_data_gen = ImageDataGenerator(rescale = 1/255)\n",
        "train_images = train_data_gen.flow_from_directory(\"./horse-or-human\", target_size = (150,150), batch_size = 128, class_mode = 'binary' )\n",
        "validation_images = Validation_data_gen.flow_from_directory(\"./validation-horse-or-human\", target_size = (150,150), batch_size = 32, class_mode = 'binary' )"
      ],
      "metadata": {
        "id": "7yR6dTT0SBer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images, steps_per_epoch = 8, epochs=10, verbose=2, validation_data = validation_images, validation_steps=8)\n"
      ],
      "metadata": {
        "id": "ymdArQakS1fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import random\n",
        "\n",
        "layers_output = [layer.output for layer in model.layers[1:]]\n",
        "visualtion_model = tf.keras.models.Model(inputs=model.input, outputs=layers_output)\n",
        "\n",
        "training_horse_images = [os.path.join(train_horses, fname) for fname in train_horses_files]\n",
        "training_human_images = [os.path.join(train_humans, fname) for fname in train_humans_files]\n",
        "\n",
        "img_path = random.choice(training_horse_images+training_human_images)\n",
        "image = load_img(img_path, target_size=(150,150))\n",
        "x = img_to_array(image)\n",
        "x = x.reshape((1,)+x.shape)\n",
        "x /= 255\n",
        "\n",
        "prediction_feature_maps = visualtion_model.predict(x, batch_size=10)\n",
        "\n",
        "layers_name = [layer.name for layer in model.layers[1:]]\n",
        "\n",
        "for layer_name, feature_map in zip(layers_name, prediction_feature_maps):\n",
        "  if len(feature_map)==4:\n",
        "    n_feature = feature_map.shape[-1]\n",
        "    size = feature_map.shape[1]\n",
        "    display_grid = np.zeros((size, size*n_feature))\n",
        "    for idx in range(n_feature):\n",
        "      x = feature_map[0,:,:,idx]\n",
        "      x-=x.mean()\n",
        "      x/=x.std()\n",
        "      x*=64\n",
        "      x+=128\n",
        "      x = np.clip(x,0,255).astype('uint8')\n",
        "      display_grid[:, idx*size:(idx+1)*size] = x\n",
        "    scale = 20./n_feature\n",
        "    plt.figure(figsize = (scale*n_feature, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, cmap = 'viridis', aspect='auto')\n"
      ],
      "metadata": {
        "id": "SAPJstIRTL5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "metadata": {
        "id": "bxO3Cr9fuMN7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}